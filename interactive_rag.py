import sys
import os

# Ensure src is in path
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.data.mock_erp import load_mock_erp_data
from src.ontology.mapper import build_knowledge_graph
from src.rag.retriever import GraphRetriever

def interactive_session():
    print("--- EBS ERP RAG ëŒ€í™”í˜• ì„¸ì…˜ ì‹œì‘ ---")
    print("ë°ì´í„° ë¡œë”© ì¤‘...")
    
    erp_data = load_mock_erp_data()
    kg = build_knowledge_graph(erp_data)
    retriever = GraphRetriever(kg)
    
    print("ì¤€ë¹„ ì™„ë£Œ! (ì¢…ë£Œí•˜ë ¤ë©´ 'exit' ë˜ëŠ” 'quit' ì…ë ¥)")
    print("ì‚¬ìš© ê°€ëŠ¥í•œ ì§ˆë¬¸ ìœ í˜•: \n 1. ê³ ê°ëª… ('EBS í…Œí¬', 'ë¯¸ë˜ í•™êµ', 'ìŠ¤íƒ€íŠ¸ì—… í—ˆë¸Œ') -> ì£¼ë¬¸/ê²°ì œ ë‚´ì—­ ì¡°íšŒ \n 2. 'ì›ìì¬' -> ì¬ê³  í˜„í™© ì¡°íšŒ")
    print("-" * 50)

    while True:
        try:
            user_input = input("\nì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” >> ").strip()
            
            if user_input.lower() in ['exit', 'quit', 'ì¢…ë£Œ']:
                print("ì„¸ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            print(f"\n[LOG] 1ï¸âƒ£  ì‚¬ìš©ì ìì—°ì–´ ì¿¼ë¦¬ ìˆ˜ì‹ : \"{user_input}\"")

            # Simple Intent Recognition (Rule-based for PoC)
            # In real system, this would be an LLM classifier
            context = ""
            print(f"[LOG] 2ï¸âƒ£  ì˜ë„ ë¶„ì„ ë° ì—”í‹°í‹° ì¶”ì¶œ ì¤‘...")
            
            # Normalize for matching (remove whitespace to handle typos like 'EBSí…Œí¬')
            user_input_norm = user_input.replace(" ", "")

            if "ì›ìì¬" in user_input_norm or "ì¬ê³ " in user_input_norm:
                print(f"[LOG]    -> ì˜ë„: ì¬ê³  í˜„í™© ì¡°íšŒ (Intent: StockCheck)")
                print(f"[LOG]    -> ì¶”ì¶œ ì—”í‹°í‹°: 'ì›ìì¬'")
                context = retriever.get_context_string("stock_check", "ì›ìì¬")
            else:
                # Assume customer query, try to find known customer names
                found_cust = None
                known_customers = ['EBS í…Œí¬', 'ë¯¸ë˜ í•™êµ', 'ì—ë“€ ì½”í”„', 'ìŠ¤íƒ€íŠ¸ì—… í—ˆë¸Œ']
                for cust in known_customers:
                    # Check matching ignoring spaces (e.g. 'ìŠ¤íƒ€íŠ¸ì—…í—ˆë¸Œ' matches 'ìŠ¤íƒ€íŠ¸ì—… í—ˆë¸Œ')
                    if cust.replace(" ", "") in user_input_norm:
                        found_cust = cust
                        break
                
                if found_cust:
                     print(f"[LOG]    -> ì˜ë„: ê³ ê° ì£¼ë¬¸ ì´ë ¥ ì¡°íšŒ (Intent: CustomerHistory)")
                     print(f"[LOG]    -> ì¶”ì¶œ ì—”í‹°í‹°: '{found_cust}'")
                     context = retriever.get_context_string("customer_history", found_cust)
                else:
                    print("[System] âš ï¸ ì§ˆë¬¸ì—ì„œ ê³ ê°ëª…ì´ë‚˜ 'ì›ìì¬' í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    print("ì˜ˆì‹œ: 'EBS í…Œí¬ ì´ë ¥ ë³´ì—¬ì¤˜', 'ì›ìì¬ ì¬ê³  ì–´ë•Œ?'")
                    continue

            print("\n[LOG] 3ï¸âƒ£  ìµœì¢… ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ (LLM ì…ë ¥ìš©):")
            print("=" * 40)
            print(context)
            print("=" * 40)
            
            # 4. Mock LLM Generation
            print(f"\n[LOG] 4ï¸âƒ£  LLM ìµœì¢… ë‹µë³€ ìƒì„± (Simulation)...")
            final_answer = mock_llm_response(user_input, context)
            print("\nğŸ¤– [AI Assistant]:", final_answer)
            print("-" * 60)
            
        except KeyboardInterrupt:
            print("\nì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        except Exception as e:
            print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

def mock_llm_response(query, context):
    """
    Simulates an LLM generating a natural language response based on the retrieved context.
    """
    if "ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤" in context:
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í•´ë‹¹ ì¡°ê±´ì— ë§ëŠ” ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    if "ë¯¸ë‚©" in context:
        return f"í˜„ì¬ ì¡°íšŒëœ ì •ë³´ì— ë”°ë¥´ë©´, í•´ë‹¹ ê³ ê°ì—ê²Œ **ë¯¸ë‚©ëœ ì£¼ë¬¸**ì´ ì¡´ì¬í•©ë‹ˆë‹¤. ì¬ë¬´ ë¦¬ìŠ¤í¬ ê´€ë¦¬ê°€ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‹ˆ ë‹´ë‹¹ ë¶€ì„œ í™•ì¸ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n(ê·¼ê±°: {context.strip()})"
        
    if "ë‚©ë¶€ì™„ë£Œ" in context:
        return f"í™•ì¸ ê²°ê³¼, í•´ë‹¹ ê³ ê°ì˜ ìµœê·¼ ì£¼ë¬¸ ê±´ë“¤ì€ ëª¨ë‘ **ì •ìƒì ìœ¼ë¡œ ê²°ì œ ì™„ë£Œ**ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ìˆ˜ ê³ ê°ìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤."
        
    if "ì›ìì¬" in context:
        # Simple extraction logic for demo
        import re
        lines = context.split('\n')
        low_stock = [line for line in lines if "5ê°œ" in line or "10ê°œ" in line] # Mock low stock logic
        
        if low_stock:
             return f"í˜„ì¬ ì›ìì¬ ì¬ê³  í˜„í™©ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ì¼ë¶€ í’ˆëª©ì˜ ì¬ê³ ê°€ ë¶€ì¡±í•´ ë³´ì…ë‹ˆë‹¤.\níŠ¹íˆ ë‹¤ìŒ í•­ëª©ì— ì£¼ì˜í•˜ì„¸ìš”: {', '.join([l.split(':')[0] for l in low_stock])}.\nìƒì‚° ì¼ì •ì— ì°¨ì§ˆì´ ì—†ë„ë¡ ë°œì£¼ê°€ í•„ìš”í•©ë‹ˆë‹¤."
        else:
             return "í˜„ì¬ ì›ìì¬ ì¬ê³ ëŠ” ìƒì‚°ì„ ì§„í–‰í•˜ê¸°ì— ì¶©ë¶„í•œ ìˆ˜ì¤€ìœ¼ë¡œ íŒŒì•…ë©ë‹ˆë‹¤."

    return "ì£„ì†¡í•©ë‹ˆë‹¤. ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ìƒì„±í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤."

if __name__ == "__main__":
    interactive_session()
